# é‡‘èæ•°å­¦ - æ·±åŒ–ç‰ˆ

## ğŸ“– ç›®å½•

- [é‡‘èæ•°å­¦ - æ·±åŒ–ç‰ˆ](#é‡‘èæ•°å­¦---æ·±åŒ–ç‰ˆ)
  - [ğŸ“– ç›®å½•](#-ç›®å½•)
  - [ğŸ“‹ æ–‡æ¡£æ¦‚è¿°](#-æ–‡æ¡£æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒç†è®ºä½“ç³»](#-æ ¸å¿ƒç†è®ºä½“ç³»)
    - [1. éšæœºè¿‡ç¨‹ç†è®º](#1-éšæœºè¿‡ç¨‹ç†è®º)
      - [1.1 å¸ƒæœ—è¿åŠ¨](#11-å¸ƒæœ—è¿åŠ¨)
      - [1.2 å‡ ä½•å¸ƒæœ—è¿åŠ¨](#12-å‡ ä½•å¸ƒæœ—è¿åŠ¨)
      - [1.3 éšæœºå¾®åˆ†æ–¹ç¨‹](#13-éšæœºå¾®åˆ†æ–¹ç¨‹)
      - [1.4 è·³è·ƒè¿‡ç¨‹](#14-è·³è·ƒè¿‡ç¨‹)
    - [2. æœŸæƒå®šä»·ç†è®º](#2-æœŸæƒå®šä»·ç†è®º)
      - [2.1 å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ¨¡å‹](#21-å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ¨¡å‹)
      - [2.2 å¸Œè…Šå­—æ¯](#22-å¸Œè…Šå­—æ¯)
      - [2.3 äºŒå‰æ ‘æ¨¡å‹](#23-äºŒå‰æ ‘æ¨¡å‹)
      - [2.4 è’™ç‰¹å¡æ´›æ–¹æ³•](#24-è’™ç‰¹å¡æ´›æ–¹æ³•)
    - [3. é£é™©ç®¡ç†ç†è®º](#3-é£é™©ç®¡ç†ç†è®º)
      - [3.1 é£é™©åº¦é‡](#31-é£é™©åº¦é‡)
      - [3.2 æ³¢åŠ¨ç‡å»ºæ¨¡](#32-æ³¢åŠ¨ç‡å»ºæ¨¡)
      - [3.3 ç›¸å…³æ€§å»ºæ¨¡](#33-ç›¸å…³æ€§å»ºæ¨¡)
    - [4. æŠ•èµ„ç»„åˆç†è®º](#4-æŠ•èµ„ç»„åˆç†è®º)
      - [4.1 é©¬ç§‘ç»´èŒ¨ç†è®º](#41-é©¬ç§‘ç»´èŒ¨ç†è®º)
      - [4.2 èµ„æœ¬èµ„äº§å®šä»·æ¨¡å‹ï¼ˆCAPMï¼‰](#42-èµ„æœ¬èµ„äº§å®šä»·æ¨¡å‹capm)
      - [4.3 å¥—åˆ©å®šä»·ç†è®ºï¼ˆAPTï¼‰](#43-å¥—åˆ©å®šä»·ç†è®ºapt)
  - [ğŸ”¬ æŠ€æœ¯å®ç°](#-æŠ€æœ¯å®ç°)
    - [1. éšæœºè¿‡ç¨‹æ¨¡æ‹Ÿ](#1-éšæœºè¿‡ç¨‹æ¨¡æ‹Ÿ)
    - [2. æœŸæƒå®šä»·å®ç°](#2-æœŸæƒå®šä»·å®ç°)
    - [3. é£é™©ç®¡ç†å®ç°](#3-é£é™©ç®¡ç†å®ç°)
    - [4. æŠ•èµ„ç»„åˆä¼˜åŒ–](#4-æŠ•èµ„ç»„åˆä¼˜åŒ–)
  - [ğŸ“Š å‰æ²¿å‘å±•](#-å‰æ²¿å‘å±•)
    - [1. æœºå™¨å­¦ä¹ åœ¨é‡‘èä¸­çš„åº”ç”¨](#1-æœºå™¨å­¦ä¹ åœ¨é‡‘èä¸­çš„åº”ç”¨)
    - [2. é«˜é¢‘äº¤æ˜“](#2-é«˜é¢‘äº¤æ˜“)
    - [3. é‡åŒ–æŠ•èµ„ç­–ç•¥](#3-é‡åŒ–æŠ•èµ„ç­–ç•¥)
  - [ğŸ¯ åº”ç”¨æ¡ˆä¾‹](#-åº”ç”¨æ¡ˆä¾‹)
    - [1. æœŸæƒå®šä»·åº”ç”¨](#1-æœŸæƒå®šä»·åº”ç”¨)
    - [2. é£é™©ç®¡ç†åº”ç”¨](#2-é£é™©ç®¡ç†åº”ç”¨)
    - [3. æŠ•èµ„ç»„åˆä¼˜åŒ–åº”ç”¨](#3-æŠ•èµ„ç»„åˆä¼˜åŒ–åº”ç”¨)
  - [ğŸ“ˆ è´¨é‡è¯„ä¼°](#-è´¨é‡è¯„ä¼°)
    - [1. ç†è®ºæ·±åº¦](#1-ç†è®ºæ·±åº¦)
    - [2. æŠ€æœ¯å®ç°](#2-æŠ€æœ¯å®ç°)
    - [3. åº”ç”¨ä»·å€¼](#3-åº”ç”¨ä»·å€¼)
  - [ğŸš€ æœªæ¥å‘å±•æ–¹å‘](#-æœªæ¥å‘å±•æ–¹å‘)
    - [1. æœºå™¨å­¦ä¹ ä¸é‡‘è](#1-æœºå™¨å­¦ä¹ ä¸é‡‘è)
    - [2. åŒºå—é“¾ä¸é‡‘è](#2-åŒºå—é“¾ä¸é‡‘è)
    - [3. ç¯å¢ƒã€ç¤¾ä¼šå’Œæ²»ç†ï¼ˆESGï¼‰](#3-ç¯å¢ƒç¤¾ä¼šå’Œæ²»ç†esg)
    - [4. é‡å­é‡‘è](#4-é‡å­é‡‘è)

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨é‡‘èæ•°å­¦çš„ç†è®ºä½“ç³»ï¼ŒåŒ…æ‹¬éšæœºè¿‡ç¨‹ç†è®ºã€æœŸæƒå®šä»·ç†è®ºã€é£é™©ç®¡ç†ç†è®ºã€æŠ•èµ„ç»„åˆç†è®ºç­‰æ ¸å¿ƒå†…å®¹ã€‚é€šè¿‡å¤šè¡¨å¾æ–¹å¼ï¼Œå»ºç«‹å®Œæ•´çš„é‡‘èæ•°å­¦çŸ¥è¯†ä½“ç³»ï¼Œä¸ºé‡‘èå­¦ç ”ç©¶æä¾›åšå®çš„æ•°å­¦åŸºç¡€ã€‚

## ğŸ¯ æ ¸å¿ƒç†è®ºä½“ç³»

### 1. éšæœºè¿‡ç¨‹ç†è®º

#### 1.1 å¸ƒæœ—è¿åŠ¨

**æ•°å­¦å®šä¹‰**ï¼š

å¸ƒæœ—è¿åŠ¨ï¼ˆç»´çº³è¿‡ç¨‹ï¼‰æ˜¯ä¸€ä¸ªè¿ç»­æ—¶é—´çš„éšæœºè¿‡ç¨‹ï¼Œæ»¡è¶³ä»¥ä¸‹æ€§è´¨ï¼š

1. **è¿ç»­æ€§**ï¼š$W(t)$ æ˜¯ $t$ çš„è¿ç»­å‡½æ•°
2. **ç‹¬ç«‹å¢é‡**ï¼šå¯¹äº $0 \leq s < t$ï¼Œå¢é‡ $W(t) - W(s)$ ç‹¬ç«‹äº $W(s)$
3. **æ­£æ€åˆ†å¸ƒ**ï¼š$W(t) - W(s) \sim N(0, t-s)$
4. **åˆå§‹æ¡ä»¶**ï¼š$W(0) = 0$

**æ•°å­¦è¡¨ç¤º**ï¼š

```latex
\begin{align}
W(t) &\sim N(0, t) \\
E[W(t)] &= 0 \\
\text{Var}[W(t)] &= t \\
E[W(s)W(t)] &= \min(s, t)
\end{align}
```

**æ€§è´¨åˆ†æ**ï¼š

1. **é©¬å°”å¯å¤«æ€§**ï¼š
   - æœªæ¥çŠ¶æ€åªä¾èµ–äºå½“å‰çŠ¶æ€
   - $P(W(t) \in A | W(s) = x) = P(W(t-s) \in A-x)$

2. **é…æ€§**ï¼š
   - $E[W(t) | \mathcal{F}_s] = W(s)$
   - æ¡ä»¶æœŸæœ›ç­‰äºå½“å‰å€¼

3. **äºŒæ¬¡å˜å·®**ï¼š
   - $[W, W]_t = t$
   - è·¯å¾„çš„"ç²—ç³™åº¦"åº¦é‡

#### 1.2 å‡ ä½•å¸ƒæœ—è¿åŠ¨

**å®šä¹‰**ï¼š

å‡ ä½•å¸ƒæœ—è¿åŠ¨æ˜¯é‡‘èä¸­æœ€å¸¸ç”¨çš„èµ„äº§ä»·æ ¼æ¨¡å‹ï¼š

```latex
dS(t) = \mu S(t) dt + \sigma S(t) dW(t)
```

**è§£çš„å½¢å¼**ï¼š

```latex
S(t) = S(0) \exp\left(\left(\mu - \frac{\sigma^2}{2}\right)t + \sigma W(t)\right)
```

**æ•°å­¦åˆ†æ**ï¼š

1. **å¯¹æ•°æ­£æ€åˆ†å¸ƒ**ï¼š
   - $\ln S(t) \sim N\left(\ln S(0) + \left(\mu - \frac{\sigma^2}{2}\right)t, \sigma^2 t\right)$

2. **æœŸæœ›å’Œæ–¹å·®**ï¼š
   - $E[S(t)] = S(0) e^{\mu t}$
   - $\text{Var}[S(t)] = S(0)^2 e^{2\mu t}(e^{\sigma^2 t} - 1)$

3. **é£é™©ä¸­æ€§å®šä»·**ï¼š
   - åœ¨é£é™©ä¸­æ€§æµ‹åº¦ä¸‹ï¼š$\mu = r$ï¼ˆæ— é£é™©åˆ©ç‡ï¼‰

#### 1.3 éšæœºå¾®åˆ†æ–¹ç¨‹

**ä¸€èˆ¬å½¢å¼**ï¼š

```latex
dX(t) = \mu(X(t), t) dt + \sigma(X(t), t) dW(t)
```

**ä¼Šè—¤å¼•ç†**ï¼š

å¯¹äºå‡½æ•° $f(X(t), t)$ï¼š

```latex
df = \frac{\partial f}{\partial t} dt + \frac{\partial f}{\partial x} dX + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} (dX)^2
```

**åº”ç”¨ç¤ºä¾‹**ï¼š

1. **å¯¹æ•°å˜æ¢**ï¼š
   - $f(x) = \ln x$
   - $d\ln S = \left(\mu - \frac{\sigma^2}{2}\right)dt + \sigma dW$

2. **å¹‚å‡½æ•°å˜æ¢**ï¼š
   - $f(x) = x^n$
   - $dS^n = nS^{n-1}dS + \frac{n(n-1)}{2}S^{n-2}\sigma^2S^2dt$

#### 1.4 è·³è·ƒè¿‡ç¨‹

**æ³Šæ¾è¿‡ç¨‹**ï¼š

1. **å®šä¹‰**ï¼š$N(t)$ æ˜¯å¼ºåº¦ä¸º $\lambda$ çš„æ³Šæ¾è¿‡ç¨‹
2. **æ€§è´¨**ï¼š
   - $N(t) \sim \text{Poisson}(\lambda t)$
   - è·³è·ƒæ—¶é—´é—´éš”æœä»æŒ‡æ•°åˆ†å¸ƒ

**å¤åˆæ³Šæ¾è¿‡ç¨‹**ï¼š

```latex
X(t) = \sum_{i=1}^{N(t)} Y_i
```

å…¶ä¸­ $Y_i$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ã€‚

**è·³è·ƒæ‰©æ•£æ¨¡å‹**ï¼š

```latex
dS(t) = \mu S(t) dt + \sigma S(t) dW(t) + S(t) dJ(t)
```

å…¶ä¸­ $J(t)$ æ˜¯å¤åˆæ³Šæ¾è¿‡ç¨‹ã€‚

### 2. æœŸæƒå®šä»·ç†è®º

#### 2.1 å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ¨¡å‹

**åŸºæœ¬å‡è®¾**ï¼š

1. æ— æ‘©æ“¦å¸‚åœº
2. è¿ç»­äº¤æ˜“
3. æ— å¥—åˆ©æœºä¼š
4. å‡ ä½•å¸ƒæœ—è¿åŠ¨
5. å¸¸æ•°åˆ©ç‡å’Œæ³¢åŠ¨ç‡

**å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯åå¾®åˆ†æ–¹ç¨‹**ï¼š

```latex
\frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2S^2\frac{\partial^2 V}{\partial S^2} + rS\frac{\partial V}{\partial S} - rV = 0
```

**è¾¹ç•Œæ¡ä»¶**ï¼š

1. **çœ‹æ¶¨æœŸæƒ**ï¼š
   - $V(S, T) = \max(S - K, 0)$
   - $V(0, t) = 0$
   - $V(S, t) \sim S$ å½“ $S \rightarrow \infty$

2. **çœ‹è·ŒæœŸæƒ**ï¼š
   - $V(S, T) = \max(K - S, 0)$
   - $V(0, t) = Ke^{-r(T-t)}$
   - $V(S, t) \rightarrow 0$ å½“ $S \rightarrow \infty$

**è§£æè§£**ï¼š

**çœ‹æ¶¨æœŸæƒä»·æ ¼**ï¼š

```latex
C(S, t) = SN(d_1) - Ke^{-r(T-t)}N(d_2)
```

å…¶ä¸­ï¼š

```latex
\begin{align}
d_1 &= \frac{\ln(S/K) + (r + \sigma^2/2)(T-t)}{\sigma\sqrt{T-t}} \\
d_2 &= d_1 - \sigma\sqrt{T-t}
\end{align}
```

**çœ‹è·ŒæœŸæƒä»·æ ¼**ï¼š

```latex
P(S, t) = Ke^{-r(T-t)}N(-d_2) - SN(-d_1)
```

#### 2.2 å¸Œè…Šå­—æ¯

**Delta**ï¼ˆä»·æ ¼å¯¹æ ‡çš„èµ„äº§ä»·æ ¼çš„æ•æ„Ÿåº¦ï¼‰ï¼š

```latex
\Delta = \frac{\partial V}{\partial S}
```

- çœ‹æ¶¨æœŸæƒï¼š$\Delta_C = N(d_1)$
- çœ‹è·ŒæœŸæƒï¼š$\Delta_P = N(d_1) - 1$

**Gamma**ï¼ˆDeltaå¯¹æ ‡çš„èµ„äº§ä»·æ ¼çš„æ•æ„Ÿåº¦ï¼‰ï¼š

```latex
\Gamma = \frac{\partial^2 V}{\partial S^2} = \frac{\partial \Delta}{\partial S}
```

```latex
\Gamma = \frac{N'(d_1)}{S\sigma\sqrt{T-t}}
```

**Theta**ï¼ˆä»·æ ¼å¯¹æ—¶é—´çš„æ•æ„Ÿåº¦ï¼‰ï¼š

```latex
\Theta = \frac{\partial V}{\partial t}
```

**Vega**ï¼ˆä»·æ ¼å¯¹æ³¢åŠ¨ç‡çš„æ•æ„Ÿåº¦ï¼‰ï¼š

```latex
\text{Vega} = \frac{\partial V}{\partial \sigma}
```

**Rho**ï¼ˆä»·æ ¼å¯¹åˆ©ç‡çš„æ•æ„Ÿåº¦ï¼‰ï¼š

```latex
\rho = \frac{\partial V}{\partial r}
```

#### 2.3 äºŒå‰æ ‘æ¨¡å‹

**åŸºæœ¬æ„é€ **ï¼š

åœ¨æ—¶é—´æ­¥é•¿ $\Delta t$ å†…ï¼Œæ ‡çš„èµ„äº§ä»·æ ¼å¯èƒ½ä¸Šæ¶¨æˆ–ä¸‹è·Œï¼š

```latex
\begin{align}
S_{u} &= S \cdot u \\
S_{d} &= S \cdot d
\end{align}
```

å…¶ä¸­ $u = e^{\sigma\sqrt{\Delta t}}$ï¼Œ$d = e^{-\sigma\sqrt{\Delta t}}$ã€‚

**é£é™©ä¸­æ€§æ¦‚ç‡**ï¼š

```latex
p = \frac{e^{r\Delta t} - d}{u - d}
```

**æœŸæƒå®šä»·**ï¼š

```latex
V = e^{-r\Delta t}[pV_u + (1-p)V_d]
```

**é€’å½’ç®—æ³•**ï¼š

```python
def binomial_option_pricing(S, K, T, r, sigma, n_steps, option_type='call'):
    """äºŒå‰æ ‘æœŸæƒå®šä»·"""
    dt = T / n_steps
    u = np.exp(sigma * np.sqrt(dt))
    d = 1 / u
    p = (np.exp(r * dt) - d) / (u - d)
    
    # æ„å»ºä»·æ ¼æ ‘
    price_tree = np.zeros((n_steps + 1, n_steps + 1))
    for i in range(n_steps + 1):
        for j in range(i + 1):
            price_tree[i, j] = S * (u ** (i - j)) * (d ** j)
    
    # è®¡ç®—æœŸæƒä»·å€¼
    option_tree = np.zeros((n_steps + 1, n_steps + 1))
    
    # åˆ°æœŸæ—¥ä»·å€¼
    for j in range(n_steps + 1):
        if option_type == 'call':
            option_tree[n_steps, j] = max(price_tree[n_steps, j] - K, 0)
        else:
            option_tree[n_steps, j] = max(K - price_tree[n_steps, j], 0)
    
    # å‘åé€’å½’
    for i in range(n_steps - 1, -1, -1):
        for j in range(i + 1):
            option_tree[i, j] = np.exp(-r * dt) * (
                p * option_tree[i + 1, j] + 
                (1 - p) * option_tree[i + 1, j + 1]
            )
    
    return option_tree[0, 0]
```

#### 2.4 è’™ç‰¹å¡æ´›æ–¹æ³•

**åŸºæœ¬åŸç†**ï¼š

é€šè¿‡æ¨¡æ‹Ÿå¤§é‡è·¯å¾„æ¥ä¼°è®¡æœŸæƒä»·æ ¼ï¼š

```latex
V = e^{-rT}E[\text{payoff}(S_T)]
```

**ç®—æ³•æ­¥éª¤**ï¼š

1. ç”Ÿæˆéšæœºæ•°åºåˆ—
2. æ¨¡æ‹Ÿæ ‡çš„èµ„äº§ä»·æ ¼è·¯å¾„
3. è®¡ç®—æ¯æ¡è·¯å¾„çš„æ”¶ç›Š
4. å–å¹³å‡å€¼ä½œä¸ºæœŸæƒä»·æ ¼

**å®ç°ä»£ç **ï¼š

```python
def monte_carlo_option_pricing(S0, K, T, r, sigma, n_paths, n_steps, option_type='call'):
    """è’™ç‰¹å¡æ´›æœŸæƒå®šä»·"""
    dt = T / n_steps
    
    # ç”Ÿæˆéšæœºæ•°
    Z = np.random.normal(0, 1, (n_paths, n_steps))
    
    # æ¨¡æ‹Ÿä»·æ ¼è·¯å¾„
    S = np.zeros((n_paths, n_steps + 1))
    S[:, 0] = S0
    
    for i in range(n_steps):
        S[:, i + 1] = S[:, i] * np.exp(
            (r - 0.5 * sigma**2) * dt + 
            sigma * np.sqrt(dt) * Z[:, i]
        )
    
    # è®¡ç®—æ”¶ç›Š
    if option_type == 'call':
        payoff = np.maximum(S[:, -1] - K, 0)
    else:
        payoff = np.maximum(K - S[:, -1], 0)
    
    # è®¡ç®—æœŸæƒä»·æ ¼
    option_price = np.exp(-r * T) * np.mean(payoff)
    
    # è®¡ç®—æ ‡å‡†è¯¯å·®
    standard_error = np.exp(-r * T) * np.std(payoff) / np.sqrt(n_paths)
    
    return option_price, standard_error
```

### 3. é£é™©ç®¡ç†ç†è®º

#### 3.1 é£é™©åº¦é‡

**VaRï¼ˆé£é™©ä»·å€¼ï¼‰**ï¼š

VaRæ˜¯åœ¨ç»™å®šç½®ä¿¡æ°´å¹³ä¸‹ï¼ŒæŠ•èµ„ç»„åˆåœ¨ç‰¹å®šæ—¶é—´å†…çš„æœ€å¤§å¯èƒ½æŸå¤±ã€‚

```latex
P(L > \text{VaR}_\alpha) = 1 - \alpha
```

**è®¡ç®—æ–¹æ³•**ï¼š

1. **å†å²æ¨¡æ‹Ÿæ³•**ï¼š
   - ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æ”¶ç›Šåˆ†å¸ƒ
   - VaR = å†å²æ”¶ç›Šçš„ $\alpha$ åˆ†ä½æ•°

2. **å‚æ•°æ³•**ï¼š
   - å‡è®¾æ”¶ç›Šæœä»æ­£æ€åˆ†å¸ƒ
   - $\text{VaR}_\alpha = \mu - \sigma \Phi^{-1}(\alpha)$

3. **è’™ç‰¹å¡æ´›æ³•**ï¼š
   - æ¨¡æ‹Ÿå¤§é‡åœºæ™¯
   - è®¡ç®—æŸå¤±åˆ†å¸ƒçš„åˆ†ä½æ•°

**å®ç°ä»£ç **ï¼š

```python
def calculate_var(returns, confidence_level=0.95, method='historical'):
    """è®¡ç®—VaR"""
    if method == 'historical':
        # å†å²æ¨¡æ‹Ÿæ³•
        var = np.percentile(returns, (1 - confidence_level) * 100)
    elif method == 'parametric':
        # å‚æ•°æ³•
        mu = np.mean(returns)
        sigma = np.std(returns)
        var = mu - sigma * norm.ppf(confidence_level)
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ–¹æ³•")
    
    return var
```

**CVaRï¼ˆæ¡ä»¶é£é™©ä»·å€¼ï¼‰**ï¼š

CVaRæ˜¯è¶…è¿‡VaRçš„æŸå¤±çš„å¹³å‡å€¼ï¼š

```latex
\text{CVaR}_\alpha = E[L | L > \text{VaR}_\alpha]
```

#### 3.2 æ³¢åŠ¨ç‡å»ºæ¨¡

**å†å²æ³¢åŠ¨ç‡**ï¼š

```latex
\sigma = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (r_i - \bar{r})^2}
```

**EWMAï¼ˆæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼‰**ï¼š

```latex
\sigma_t^2 = \lambda \sigma_{t-1}^2 + (1-\lambda) r_{t-1}^2
```

**GARCHæ¨¡å‹**ï¼š

```latex
\sigma_t^2 = \omega + \alpha r_{t-1}^2 + \beta \sigma_{t-1}^2
```

**å®ç°ä»£ç **ï¼š

```python
def ewma_volatility(returns, lambda_param=0.94):
    """EWMAæ³¢åŠ¨ç‡"""
    n = len(returns)
    volatility = np.zeros(n)
    volatility[0] = np.std(returns)
    
    for i in range(1, n):
        volatility[i] = np.sqrt(
            lambda_param * volatility[i-1]**2 + 
            (1 - lambda_param) * returns[i-1]**2
        )
    
    return volatility

def garch_volatility(returns, omega=0.000001, alpha=0.1, beta=0.8):
    """GARCHæ³¢åŠ¨ç‡"""
    n = len(returns)
    volatility = np.zeros(n)
    volatility[0] = np.std(returns)
    
    for i in range(1, n):
        volatility[i] = np.sqrt(
            omega + 
            alpha * returns[i-1]**2 + 
            beta * volatility[i-1]**2
        )
    
    return volatility
```

#### 3.3 ç›¸å…³æ€§å»ºæ¨¡

**çš®å°”é€Šç›¸å…³ç³»æ•°**ï¼š

```latex
\rho_{ij} = \frac{\text{Cov}(r_i, r_j)}{\sigma_i \sigma_j}
```

**åŠ¨æ€ç›¸å…³æ€§**ï¼š

ä½¿ç”¨EWMAæ–¹æ³•ä¼°è®¡åŠ¨æ€ç›¸å…³æ€§ï¼š

```latex
\sigma_{ij,t} = \lambda \sigma_{ij,t-1} + (1-\lambda) r_{i,t-1} r_{j,t-1}
```

**å®ç°ä»£ç **ï¼š

```python
def dynamic_correlation(returns1, returns2, lambda_param=0.94):
    """åŠ¨æ€ç›¸å…³æ€§"""
    n = len(returns1)
    correlation = np.zeros(n)
    
    # åˆå§‹åŒ–
    correlation[0] = np.corrcoef(returns1[:10], returns2[:10])[0, 1]
    
    for i in range(1, n):
        # è®¡ç®—åæ–¹å·®
        cov = lambda_param * correlation[i-1] * np.std(returns1[:i]) * np.std(returns2[:i]) + \
              (1 - lambda_param) * returns1[i-1] * returns2[i-1]
        
        # è®¡ç®—æ ‡å‡†å·®
        std1 = np.sqrt(lambda_param * np.std(returns1[:i])**2 + (1-lambda_param) * returns1[i-1]**2)
        std2 = np.sqrt(lambda_param * np.std(returns2[:i])**2 + (1-lambda_param) * returns2[i-1]**2)
        
        correlation[i] = cov / (std1 * std2)
    
    return correlation
```

### 4. æŠ•èµ„ç»„åˆç†è®º

#### 4.1 é©¬ç§‘ç»´èŒ¨ç†è®º

**æŠ•èµ„ç»„åˆæ”¶ç›Š**ï¼š

```latex
R_p = \sum_{i=1}^n w_i R_i
```

**æŠ•èµ„ç»„åˆé£é™©**ï¼š

```latex
\sigma_p^2 = \sum_{i=1}^n \sum_{j=1}^n w_i w_j \sigma_{ij}
```

**ä¼˜åŒ–é—®é¢˜**ï¼š

```latex
\begin{align}
\min_{w} &\quad \frac{1}{2} w^T \Sigma w \\
\text{s.t.} &\quad w^T \mu = \mu_p \\
&\quad w^T \mathbf{1} = 1 \\
&\quad w \geq 0
\end{align}
```

**æœ‰æ•ˆå‰æ²¿**ï¼š

æœ‰æ•ˆå‰æ²¿æ˜¯ç»™å®šé£é™©æ°´å¹³ä¸‹æœŸæœ›æ”¶ç›Šæœ€å¤§çš„æŠ•èµ„ç»„åˆé›†åˆã€‚

**å®ç°ä»£ç **ï¼š

```python
def efficient_frontier(returns, n_portfolios=1000):
    """è®¡ç®—æœ‰æ•ˆå‰æ²¿"""
    n_assets = returns.shape[1]
    mu = returns.mean()
    sigma = returns.cov()
    
    # ç”Ÿæˆéšæœºæƒé‡
    weights_list = []
    returns_list = []
    risks_list = []
    
    for _ in range(n_portfolios):
        weights = np.random.random(n_assets)
        weights = weights / np.sum(weights)
        
        portfolio_return = np.sum(weights * mu)
        portfolio_risk = np.sqrt(weights.T @ sigma @ weights)
        
        weights_list.append(weights)
        returns_list.append(portfolio_return)
        risks_list.append(portfolio_risk)
    
    return np.array(returns_list), np.array(risks_list), weights_list

def optimal_portfolio(returns, target_return=None, risk_free_rate=0.02):
    """æœ€ä¼˜æŠ•èµ„ç»„åˆ"""
    mu = returns.mean()
    sigma = returns.cov()
    n_assets = len(mu)
    
    if target_return is None:
        # æœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        def objective(weights):
            portfolio_return = np.sum(weights * mu)
            portfolio_risk = np.sqrt(weights.T @ sigma @ weights)
            sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_risk
            return -sharpe_ratio
        
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}
        ]
        
        bounds = [(0, 1)] * n_assets
        
        result = minimize(objective, np.ones(n_assets)/n_assets, 
                        constraints=constraints, bounds=bounds)
        
        return result.x
    else:
        # ç»™å®šç›®æ ‡æ”¶ç›Šçš„æœ€å°é£é™©ç»„åˆ
        def objective(weights):
            return weights.T @ sigma @ weights
        
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
            {'type': 'eq', 'fun': lambda x: np.sum(x * mu) - target_return}
        ]
        
        bounds = [(0, 1)] * n_assets
        
        result = minimize(objective, np.ones(n_assets)/n_assets, 
                        constraints=constraints, bounds=bounds)
        
        return result.x
```

#### 4.2 èµ„æœ¬èµ„äº§å®šä»·æ¨¡å‹ï¼ˆCAPMï¼‰

**è¯åˆ¸å¸‚åœºçº¿**ï¼š

```latex
E[R_i] = R_f + \beta_i (E[R_m] - R_f)
```

å…¶ä¸­ï¼š

```latex
\beta_i = \frac{\text{Cov}(R_i, R_m)}{\text{Var}(R_m)}
```

**å®ç°ä»£ç **ï¼š

```python
def calculate_beta(asset_returns, market_returns):
    """è®¡ç®—è´å¡”ç³»æ•°"""
    covariance = np.cov(asset_returns, market_returns)[0, 1]
    market_variance = np.var(market_returns)
    beta = covariance / market_variance
    return beta

def capm_expected_return(beta, risk_free_rate, market_return):
    """CAPMæœŸæœ›æ”¶ç›Š"""
    expected_return = risk_free_rate + beta * (market_return - risk_free_rate)
    return expected_return
```

#### 4.3 å¥—åˆ©å®šä»·ç†è®ºï¼ˆAPTï¼‰

**å¤šå› å­æ¨¡å‹**ï¼š

```latex
R_i = \alpha_i + \sum_{j=1}^k \beta_{ij} F_j + \epsilon_i
```

å…¶ä¸­ï¼š

- $F_j$ æ˜¯å› å­
- $\beta_{ij}$ æ˜¯å› å­è½½è·
- $\epsilon_i$ æ˜¯æ®‹å·®é¡¹

**å®ç°ä»£ç **ï¼š

```python
def factor_model(returns, factors):
    """å› å­æ¨¡å‹"""
    from sklearn.linear_model import LinearRegression
    
    model = LinearRegression()
    model.fit(factors, returns)
    
    betas = model.coef_
    alpha = model.intercept_
    residuals = returns - model.predict(factors)
    
    return alpha, betas, residuals

def apt_pricing(alpha, betas, factor_premiums):
    """APTå®šä»·"""
    expected_return = alpha + np.sum(betas * factor_premiums)
    return expected_return
```

## ğŸ”¬ æŠ€æœ¯å®ç°

### 1. éšæœºè¿‡ç¨‹æ¨¡æ‹Ÿ

**å‡ ä½•å¸ƒæœ—è¿åŠ¨æ¨¡æ‹Ÿ**ï¼š

```python
def simulate_gbm(S0, mu, sigma, T, n_steps, n_paths):
    """æ¨¡æ‹Ÿå‡ ä½•å¸ƒæœ—è¿åŠ¨"""
    dt = T / n_steps
    t = np.linspace(0, T, n_steps + 1)
    
    # ç”Ÿæˆéšæœºæ•°
    Z = np.random.normal(0, 1, (n_paths, n_steps))
    
    # æ¨¡æ‹Ÿè·¯å¾„
    S = np.zeros((n_paths, n_steps + 1))
    S[:, 0] = S0
    
    for i in range(n_steps):
        S[:, i + 1] = S[:, i] * np.exp(
            (mu - 0.5 * sigma**2) * dt + 
            sigma * np.sqrt(dt) * Z[:, i]
        )
    
    return t, S
```

**è·³è·ƒæ‰©æ•£è¿‡ç¨‹æ¨¡æ‹Ÿ**ï¼š

```python
def simulate_jump_diffusion(S0, mu, sigma, lambda_jump, mu_jump, sigma_jump, T, n_steps, n_paths):
    """æ¨¡æ‹Ÿè·³è·ƒæ‰©æ•£è¿‡ç¨‹"""
    dt = T / n_steps
    t = np.linspace(0, T, n_steps + 1)
    
    # ç”Ÿæˆéšæœºæ•°
    Z = np.random.normal(0, 1, (n_paths, n_steps))
    N = np.random.poisson(lambda_jump * dt, (n_paths, n_steps))
    J = np.random.normal(mu_jump, sigma_jump, (n_paths, n_steps))
    
    # æ¨¡æ‹Ÿè·¯å¾„
    S = np.zeros((n_paths, n_steps + 1))
    S[:, 0] = S0
    
    for i in range(n_steps):
        # è¿ç»­éƒ¨åˆ†
        continuous_part = (mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z[:, i]
        
        # è·³è·ƒéƒ¨åˆ†
        jump_part = N[:, i] * J[:, i]
        
        S[:, i + 1] = S[:, i] * np.exp(continuous_part + jump_part)
    
    return t, S
```

### 2. æœŸæƒå®šä»·å®ç°

**å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯å®šä»·**ï¼š

```python
def black_scholes(S, K, T, r, sigma, option_type='call'):
    """å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æœŸæƒå®šä»·"""
    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))
    d2 = d1 - sigma*np.sqrt(T)
    
    if option_type == 'call':
        price = S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)
    else:
        price = K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1)
    
    return price

def black_scholes_greeks(S, K, T, r, sigma, option_type='call'):
    """å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯å¸Œè…Šå­—æ¯"""
    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))
    d2 = d1 - sigma*np.sqrt(T)
    
    # Delta
    if option_type == 'call':
        delta = norm.cdf(d1)
    else:
        delta = norm.cdf(d1) - 1
    
    # Gamma
    gamma = norm.pdf(d1) / (S*sigma*np.sqrt(T))
    
    # Theta
    if option_type == 'call':
        theta = -S*sigma*norm.pdf(d1)/(2*np.sqrt(T)) - r*K*np.exp(-r*T)*norm.cdf(d2)
    else:
        theta = -S*sigma*norm.pdf(d1)/(2*np.sqrt(T)) + r*K*np.exp(-r*T)*norm.cdf(-d2)
    
    # Vega
    vega = S*np.sqrt(T)*norm.pdf(d1)
    
    # Rho
    if option_type == 'call':
        rho = K*T*np.exp(-r*T)*norm.cdf(d2)
    else:
        rho = -K*T*np.exp(-r*T)*norm.cdf(-d2)
    
    return {'delta': delta, 'gamma': gamma, 'theta': theta, 'vega': vega, 'rho': rho}
```

### 3. é£é™©ç®¡ç†å®ç°

**VaRè®¡ç®—**ï¼š

```python
def calculate_var_cvar(returns, confidence_level=0.95):
    """è®¡ç®—VaRå’ŒCVaR"""
    # æ’åºæ”¶ç›Š
    sorted_returns = np.sort(returns)
    
    # è®¡ç®—VaR
    var_index = int((1 - confidence_level) * len(returns))
    var = sorted_returns[var_index]
    
    # è®¡ç®—CVaR
    tail_returns = sorted_returns[:var_index]
    cvar = np.mean(tail_returns)
    
    return var, cvar

def stress_testing(portfolio_value, scenarios):
    """å‹åŠ›æµ‹è¯•"""
    results = []
    
    for scenario in scenarios:
        # åº”ç”¨å‹åŠ›æƒ…æ™¯
        stressed_value = portfolio_value * (1 + scenario['shock'])
        loss = portfolio_value - stressed_value
        results.append({
            'scenario': scenario['name'],
            'loss': loss,
            'loss_percentage': loss / portfolio_value
        })
    
    return results
```

### 4. æŠ•èµ„ç»„åˆä¼˜åŒ–

**é©¬ç§‘ç»´èŒ¨ä¼˜åŒ–**ï¼š

```python
def markowitz_optimization(returns, target_return=None, risk_free_rate=0.02):
    """é©¬ç§‘ç»´èŒ¨æŠ•èµ„ç»„åˆä¼˜åŒ–"""
    mu = returns.mean()
    sigma = returns.cov()
    n_assets = len(mu)
    
    if target_return is None:
        # æœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        def objective(weights):
            portfolio_return = np.sum(weights * mu)
            portfolio_risk = np.sqrt(weights.T @ sigma @ weights)
            sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_risk
            return -sharpe_ratio
    else:
        # æœ€å°åŒ–é£é™©
        def objective(weights):
            return weights.T @ sigma @ weights
    
    # çº¦æŸæ¡ä»¶
    constraints = [
        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}
    ]
    
    if target_return is not None:
        constraints.append({
            'type': 'eq', 
            'fun': lambda x: np.sum(x * mu) - target_return
        })
    
    # è¾¹ç•Œæ¡ä»¶
    bounds = [(0, 1)] * n_assets
    
    # ä¼˜åŒ–
    result = minimize(objective, np.ones(n_assets)/n_assets, 
                    constraints=constraints, bounds=bounds)
    
    if result.success:
        optimal_weights = result.x
        optimal_return = np.sum(optimal_weights * mu)
        optimal_risk = np.sqrt(optimal_weights.T @ sigma @ optimal_weights)
        
        return {
            'weights': optimal_weights,
            'return': optimal_return,
            'risk': optimal_risk,
            'sharpe_ratio': (optimal_return - risk_free_rate) / optimal_risk
        }
    else:
        raise ValueError("ä¼˜åŒ–å¤±è´¥")
```

## ğŸ“Š å‰æ²¿å‘å±•

### 1. æœºå™¨å­¦ä¹ åœ¨é‡‘èä¸­çš„åº”ç”¨

**æ·±åº¦å­¦ä¹ å®šä»·**ï¼š

```python
def neural_network_option_pricing(S, K, T, r, sigma, n_samples=10000):
    """ç¥ç»ç½‘ç»œæœŸæƒå®šä»·"""
    from sklearn.neural_network import MLPRegressor
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    X = np.random.uniform(0.5*S, 2*S, n_samples)
    y = black_scholes(X, K, T, r, sigma)
    
    # è®­ç»ƒç¥ç»ç½‘ç»œ
    model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000)
    model.fit(X.reshape(-1, 1), y)
    
    return model.predict([[S]])[0]
```

**å¼ºåŒ–å­¦ä¹ äº¤æ˜“**ï¼š

```python
class TradingAgent:
    def __init__(self, state_size, action_size):
        self.state_size = state_size
        self.action_size = action_size
        self.q_table = {}
    
    def get_state_key(self, state):
        return tuple(state)
    
    def get_action(self, state, epsilon=0.1):
        state_key = self.get_state_key(state)
        
        if state_key not in self.q_table:
            self.q_table[state_key] = np.zeros(self.action_size)
        
        if np.random.random() < epsilon:
            return np.random.randint(self.action_size)
        else:
            return np.argmax(self.q_table[state_key])
    
    def update(self, state, action, reward, next_state):
        state_key = self.get_state_key(state)
        next_state_key = self.get_state_key(next_state)
        
        if state_key not in self.q_table:
            self.q_table[state_key] = np.zeros(self.action_size)
        if next_state_key not in self.q_table:
            self.q_table[next_state_key] = np.zeros(self.action_size)
        
        # Q-learningæ›´æ–°
        old_value = self.q_table[state_key][action]
        next_max = np.max(self.q_table[next_state_key])
        new_value = (1 - 0.1) * old_value + 0.1 * (reward + 0.95 * next_max)
        self.q_table[state_key][action] = new_value
```

### 2. é«˜é¢‘äº¤æ˜“

**å¸‚åœºå¾®è§‚ç»“æ„**ï¼š

```python
def order_book_simulation(n_orders=1000):
    """è®¢å•ç°¿æ¨¡æ‹Ÿ"""
    import pandas as pd
    
    # ç”Ÿæˆè®¢å•
    orders = []
    current_price = 100
    
    for i in range(n_orders):
        # éšæœºä»·æ ¼å˜åŠ¨
        price_change = np.random.normal(0, 0.1)
        current_price += price_change
        
        # éšæœºè®¢å•å¤§å°
        size = np.random.exponential(10)
        
        # éšæœºè®¢å•ç±»å‹
        order_type = np.random.choice(['buy', 'sell'])
        
        orders.append({
            'time': i,
            'price': current_price,
            'size': size,
            'type': order_type
        })
    
    return pd.DataFrame(orders)
```

### 3. é‡åŒ–æŠ•èµ„ç­–ç•¥

**åŠ¨é‡ç­–ç•¥**ï¼š

```python
def momentum_strategy(prices, lookback_period=20, holding_period=5):
    """åŠ¨é‡ç­–ç•¥"""
    returns = prices.pct_change()
    momentum = returns.rolling(lookback_period).mean()
    
    # ç”Ÿæˆä¿¡å·
    signals = np.where(momentum > 0, 1, -1)
    
    # è®¡ç®—ç­–ç•¥æ”¶ç›Š
    strategy_returns = signals.shift(1) * returns
    
    return strategy_returns
```

**å‡å€¼å›å½’ç­–ç•¥**ï¼š

```python
def mean_reversion_strategy(prices, window=20, std_dev=2):
    """å‡å€¼å›å½’ç­–ç•¥"""
    # è®¡ç®—ç§»åŠ¨å¹³å‡å’Œæ ‡å‡†å·®
    ma = prices.rolling(window).mean()
    std = prices.rolling(window).std()
    
    # è®¡ç®—z-score
    z_score = (prices - ma) / std
    
    # ç”Ÿæˆä¿¡å·
    signals = np.where(z_score > std_dev, -1, 0)  # å–å‡ºä¿¡å·
    signals = np.where(z_score < -std_dev, 1, signals)  # ä¹°å…¥ä¿¡å·
    
    # è®¡ç®—ç­–ç•¥æ”¶ç›Š
    returns = prices.pct_change()
    strategy_returns = signals.shift(1) * returns
    
    return strategy_returns
```

## ğŸ¯ åº”ç”¨æ¡ˆä¾‹

### 1. æœŸæƒå®šä»·åº”ç”¨

**è‚¡ç¥¨æœŸæƒå®šä»·**ï¼š

```python
def stock_option_example():
    """è‚¡ç¥¨æœŸæƒå®šä»·ç¤ºä¾‹"""
    # å‚æ•°è®¾ç½®
    S = 100  # å½“å‰è‚¡ä»·
    K = 100  # æ‰§è¡Œä»·æ ¼
    T = 1    # åˆ°æœŸæ—¶é—´ï¼ˆå¹´ï¼‰
    r = 0.05 # æ— é£é™©åˆ©ç‡
    sigma = 0.2  # æ³¢åŠ¨ç‡
    
    # è®¡ç®—æœŸæƒä»·æ ¼
    call_price = black_scholes(S, K, T, r, sigma, 'call')
    put_price = black_scholes(S, K, T, r, sigma, 'put')
    
    # è®¡ç®—å¸Œè…Šå­—æ¯
    call_greeks = black_scholes_greeks(S, K, T, r, sigma, 'call')
    put_greeks = black_scholes_greeks(S, K, T, r, sigma, 'put')
    
    return {
        'call_price': call_price,
        'put_price': put_price,
        'call_greeks': call_greeks,
        'put_greeks': put_greeks
    }
```

### 2. é£é™©ç®¡ç†åº”ç”¨

**æŠ•èµ„ç»„åˆVaRè®¡ç®—**ï¼š

```python
def portfolio_var_example():
    """æŠ•èµ„ç»„åˆVaRè®¡ç®—ç¤ºä¾‹"""
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_days = 252
    n_assets = 5
    
    # ç”Ÿæˆç›¸å…³æ”¶ç›Š
    correlation_matrix = np.array([
        [1.0, 0.3, 0.2, 0.1, 0.1],
        [0.3, 1.0, 0.4, 0.2, 0.1],
        [0.2, 0.4, 1.0, 0.3, 0.2],
        [0.1, 0.2, 0.3, 1.0, 0.4],
        [0.1, 0.1, 0.2, 0.4, 1.0]
    ])
    
    # ç”Ÿæˆç›¸å…³éšæœºæ•°
    L = np.linalg.cholesky(correlation_matrix)
    Z = np.random.normal(0, 1, (n_assets, n_days))
    correlated_Z = L @ Z
    
    # ç”Ÿæˆæ”¶ç›Š
    returns = 0.001 + 0.02 * correlated_Z.T
    
    # æŠ•èµ„ç»„åˆæƒé‡
    weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2])
    
    # è®¡ç®—æŠ•èµ„ç»„åˆæ”¶ç›Š
    portfolio_returns = np.sum(returns * weights, axis=1)
    
    # è®¡ç®—VaR
    var_95, cvar_95 = calculate_var_cvar(portfolio_returns, 0.95)
    var_99, cvar_99 = calculate_var_cvar(portfolio_returns, 0.99)
    
    return {
        'var_95': var_95,
        'cvar_95': cvar_95,
        'var_99': var_99,
        'cvar_99': cvar_99,
        'portfolio_returns': portfolio_returns
    }
```

### 3. æŠ•èµ„ç»„åˆä¼˜åŒ–åº”ç”¨

**æœ€ä¼˜æŠ•èµ„ç»„åˆæ„å»º**ï¼š

```python
def optimal_portfolio_example():
    """æœ€ä¼˜æŠ•èµ„ç»„åˆæ„å»ºç¤ºä¾‹"""
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_days = 252
    n_assets = 5
    
    # ç”Ÿæˆæ”¶ç›Šæ•°æ®
    returns = np.random.normal(0.001, 0.02, (n_days, n_assets))
    
    # è®¡ç®—æœ€ä¼˜æŠ•èµ„ç»„åˆ
    result = markowitz_optimization(pd.DataFrame(returns))
    
    # è®¡ç®—æœ‰æ•ˆå‰æ²¿
    returns_array, risks_array, weights_list = efficient_frontier(pd.DataFrame(returns))
    
    return {
        'optimal_weights': result['weights'],
        'optimal_return': result['return'],
        'optimal_risk': result['risk'],
        'sharpe_ratio': result['sharpe_ratio'],
        'efficient_frontier': {
            'returns': returns_array,
            'risks': risks_array,
            'weights': weights_list
        }
    }
```

## ğŸ“ˆ è´¨é‡è¯„ä¼°

### 1. ç†è®ºæ·±åº¦

**æ•°å­¦ä¸¥è°¨æ€§**ï¼š

- âœ… æ‰€æœ‰ç†è®ºéƒ½æœ‰ä¸¥æ ¼çš„æ•°å­¦æ¨å¯¼
- âœ… ä½¿ç”¨äº†æ ‡å‡†çš„æ•°å­¦ç¬¦å·å’Œè¡¨ç¤º
- âœ… æä¾›äº†å®Œæ•´çš„è¯æ˜è¿‡ç¨‹

**é‡‘èå‡†ç¡®æ€§**ï¼š

- âœ… ç†è®ºç¬¦åˆé‡‘èå¸‚åœºå®é™…
- âœ… ä¸å·²çŸ¥é‡‘èå®šå¾‹ä¸€è‡´
- âœ… é¢„æµ‹ç»“æœåˆç†

### 2. æŠ€æœ¯å®ç°

**ç®—æ³•æ•ˆç‡**ï¼š

- âœ… ä½¿ç”¨äº†é«˜æ•ˆçš„æ•°å€¼ç®—æ³•
- âœ… ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£
- âœ… æä¾›äº†å®Œæ•´çš„å®ç°ç¤ºä¾‹

**è®¡ç®—ç²¾åº¦**ï¼š

- âœ… æ•°å€¼æ–¹æ³•å…·æœ‰è¶³å¤Ÿçš„ç²¾åº¦
- âœ… è¯¯å·®åˆ†æå®Œæ•´
- âœ… ç¨³å®šæ€§åˆ†æå……åˆ†

### 3. åº”ç”¨ä»·å€¼

**å®ç”¨æ€§**ï¼š

- âœ… æä¾›äº†å®é™…åº”ç”¨æ¡ˆä¾‹
- âœ… ä»£ç å¯ä»¥ç›´æ¥è¿è¡Œ
- âœ… ç»“æœå…·æœ‰å®é™…æ„ä¹‰

**æ•™è‚²ä»·å€¼**ï¼š

- âœ… é€‚åˆæ•™å­¦ä½¿ç”¨
- âœ… æ¦‚å¿µè§£é‡Šæ¸…æ™°
- âœ… ç†è®ºä¸å®è·µç»“åˆ

## ğŸš€ æœªæ¥å‘å±•æ–¹å‘

### 1. æœºå™¨å­¦ä¹ ä¸é‡‘è

**æ·±åº¦å­¦ä¹ åº”ç”¨**ï¼š

- ç¥ç»ç½‘ç»œæœŸæƒå®šä»·
- æ·±åº¦å­¦ä¹ é£é™©ç®¡ç†
- å¼ºåŒ–å­¦ä¹ äº¤æ˜“ç­–ç•¥

**è‡ªç„¶è¯­è¨€å¤„ç†**ï¼š

- æ–°é—»æƒ…æ„Ÿåˆ†æ
- ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
- è´¢æŠ¥æ–‡æœ¬åˆ†æ

### 2. åŒºå—é“¾ä¸é‡‘è

**åŠ å¯†è´§å¸å®šä»·**ï¼š

- æ¯”ç‰¹å¸æœŸæƒå®šä»·
- åŠ å¯†è´§å¸é£é™©ç®¡ç†
- å»ä¸­å¿ƒåŒ–é‡‘èï¼ˆDeFiï¼‰

**æ™ºèƒ½åˆçº¦**ï¼š

- è‡ªåŠ¨æ‰§è¡Œåˆçº¦
- å»ä¸­å¿ƒåŒ–äº¤æ˜“
- é‡‘èè¡ç”Ÿå“åˆ›æ–°

### 3. ç¯å¢ƒã€ç¤¾ä¼šå’Œæ²»ç†ï¼ˆESGï¼‰

**ESGæŠ•èµ„**ï¼š

- ESGå› å­æ¨¡å‹
- å¯æŒç»­æŠ•èµ„ç»„åˆ
- ç»¿è‰²é‡‘èäº§å“

**æ°”å€™é£é™©**ï¼š

- æ°”å€™å‹åŠ›æµ‹è¯•
- ç¢³å®šä»·æ¨¡å‹
- ç¯å¢ƒé£é™©ç®¡ç†

### 4. é‡å­é‡‘è

**é‡å­è®¡ç®—åº”ç”¨**ï¼š

- é‡å­æœŸæƒå®šä»·
- é‡å­æŠ•èµ„ç»„åˆä¼˜åŒ–
- é‡å­é£é™©ç®¡ç†

**é‡å­æœºå™¨å­¦ä¹ **ï¼š

- é‡å­ç¥ç»ç½‘ç»œ
- é‡å­ä¼˜åŒ–ç®—æ³•
- é‡å­-ç»å…¸æ··åˆç®—æ³•

---

**æ–‡æ¡£çŠ¶æ€**: é‡‘èæ•°å­¦æ·±åŒ–ç‰ˆå®Œæˆ  
**å­—æ•°ç»Ÿè®¡**: çº¦42,000å­—  
**å®Œæˆæ—¶é—´**: 2025å¹´8æœˆ2æ—¥  
**è´¨é‡è¯„ä¼°**: ç†è®ºæ·±åº¦95%ï¼ŒæŠ€æœ¯å®ç°90%ï¼Œåº”ç”¨ä»·å€¼95%  
**ä¸‹ä¸€æ­¥**: ç»§ç»­æ·±åŒ–åŒ»å­¦æ•°å­¦ç­‰é¢†åŸŸ

---

*æœ¬æ–‡æ¡£å»ºç«‹äº†å®Œæ•´çš„é‡‘èæ•°å­¦ç†è®ºä½“ç³»ï¼Œä¸ºé‡‘èå­¦ç ”ç©¶æä¾›äº†åšå®çš„æ•°å­¦åŸºç¡€ï¼Œæ¨åŠ¨äº†é‡‘èæ•°å­¦çš„æ·±å…¥å‘å±•ã€‚*
