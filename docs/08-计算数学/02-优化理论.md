# 2. 优化理论 / Optimization Theory

## 2.1 概述 / Overview

优化理论是研究在给定约束条件下寻找最优解的方法论。它在数学、工程、经济学和计算机科学等领域有广泛应用，是现代应用数学的核心分支之一。

## 2.2 基本概念 / Basic Concepts

### 2.2.1 优化问题 / Optimization Problem

**定义 2.1** (优化问题 / Optimization Problem)
标准优化问题形式为：
$$\min_{x \in \mathbb{R}^n} f(x)$$
$$\text{subject to } g_i(x) \leq 0, \quad i = 1, \ldots, m$$
$$\quad \quad \quad \quad h_j(x) = 0, \quad j = 1, \ldots, p$$

其中：

- $f: \mathbb{R}^n \to \mathbb{R}$ 是目标函数
- $g_i: \mathbb{R}^n \to \mathbb{R}$ 是不等式约束
- $h_j: \mathbb{R}^n \to \mathbb{R}$ 是等式约束

### 2.2.2 可行域 / Feasible Region

**定义 2.2** (可行域 / Feasible Region)
可行域是满足所有约束的点的集合：
$$\mathcal{F} = \{x \in \mathbb{R}^n : g_i(x) \leq 0, h_j(x) = 0, \forall i, j\}$$

### 2.2.3 最优解 / Optimal Solution

**定义 2.3** (全局最优解 / Global Optimal Solution)
$x^*$ 是全局最优解，如果：
$$f(x^*) \leq f(x), \quad \forall x \in \mathcal{F}$$

**定义 2.4** (局部最优解 / Local Optimal Solution)
$x^*$ 是局部最优解，如果存在 $\epsilon > 0$，使得：
$$f(x^*) \leq f(x), \quad \forall x \in \mathcal{F} \cap B_\epsilon(x^*)$$

## 2.3 凸优化 / Convex Optimization

### 2.3.1 凸集与凸函数 / Convex Sets and Functions

**定义 2.5** (凸集 / Convex Set)
集合 $C \subseteq \mathbb{R}^n$ 是凸集，如果：
$$\lambda x + (1-\lambda)y \in C, \quad \forall x, y \in C, \lambda \in [0, 1]$$

**定义 2.6** (凸函数 / Convex Function)
函数 $f: \mathbb{R}^n \to \mathbb{R}$ 是凸函数，如果：
$$f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y), \quad \forall x, y \in \mathbb{R}^n, \lambda \in [0, 1]$$

### 2.3.2 凸优化问题 / Convex Optimization Problem

**定义 2.7** (凸优化问题 / Convex Optimization Problem)
凸优化问题是形式为：
$$\min_{x \in \mathbb{R}^n} f(x)$$
$$\text{subject to } g_i(x) \leq 0, \quad i = 1, \ldots, m$$
$$\quad \quad \quad \quad Ax = b$$

其中 $f$ 和 $g_i$ 都是凸函数，$A \in \mathbb{R}^{p \times n}$。

**定理 2.1** (凸优化的局部最优性 / Local Optimality in Convex Optimization)
在凸优化问题中，局部最优解也是全局最优解。

## 2.4 拉格朗日对偶 / Lagrangian Duality

### 2.4.1 拉格朗日函数 / Lagrangian Function

**定义 2.8** (拉格朗日函数 / Lagrangian Function)
对于优化问题，拉格朗日函数定义为：
$$\mathcal{L}(x, \lambda, \mu) = f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{j=1}^p \mu_j h_j(x)$$

其中 $\lambda_i \geq 0$ 是拉格朗日乘子。

### 2.4.2 对偶函数 / Dual Function

**定义 2.9** (对偶函数 / Dual Function)
对偶函数定义为：
$$g(\lambda, \mu) = \inf_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \mu)$$

### 2.4.3 对偶问题 / Dual Problem

**定义 2.10** (对偶问题 / Dual Problem)
对偶问题是：
$$\max_{\lambda \geq 0, \mu} g(\lambda, \mu)$$

**定理 2.2** (弱对偶性 / Weak Duality)
对偶问题的目标函数值不超过原问题的最优值：
$$g(\lambda, \mu) \leq f(x^*), \quad \forall \lambda \geq 0, \mu$$

## 2.5 最优性条件 / Optimality Conditions

### 2.5.1 一阶必要条件 / First-Order Necessary Conditions

**定理 2.3** (KKT条件 / KKT Conditions)
如果 $x^*$ 是正则点且是局部最优解，则存在拉格朗日乘子 $\lambda^* \geq 0$ 和 $\mu^*$，使得：

1. **平稳性**：$\nabla f(x^*) + \sum_{i=1}^m \lambda_i^* \nabla g_i(x^*) + \sum_{j=1}^p \mu_j^* \nabla h_j(x^*) = 0$
2. **原始可行性**：$g_i(x^*) \leq 0, h_j(x^*) = 0$
3. **对偶可行性**：$\lambda_i^* \geq 0$
4. **互补松弛性**：$\lambda_i^* g_i(x^*) = 0$

### 2.5.2 二阶充分条件 / Second-Order Sufficient Conditions

**定理 2.4** (二阶充分条件 / Second-Order Sufficient Conditions)
如果 $x^*$ 满足KKT条件，且对任意非零向量 $d$ 满足：
$$d^T \nabla^2 f(x^*) d > 0$$

则 $x^*$ 是严格局部最优解。

## 2.6 算法 / Algorithms

### 2.6.1 梯度下降法 / Gradient Descent

**算法 2.1** (梯度下降法 / Gradient Descent)

```python
def gradient_descent(f, grad_f, x0, alpha, max_iter):
    x = x0
    for k in range(max_iter):
        x = x - alpha * grad_f(x)
    return x
```

**收敛性**：

- 如果 $f$ 是凸函数且 $\nabla f$ 是Lipschitz连续的，则梯度下降法收敛到全局最优解
- 收敛速度为 $O(1/k)$

### 2.6.2 牛顿法 / Newton's Method

**算法 2.2** (牛顿法 / Newton's Method)

```python
def newton_method(f, grad_f, hess_f, x0, max_iter):
    x = x0
    for k in range(max_iter):
        H = hess_f(x)
        g = grad_f(x)
        d = -np.linalg.solve(H, g)
        x = x + d
    return x
```

**收敛性**：

- 如果 $f$ 是强凸函数，则牛顿法具有二次收敛性
- 收敛速度为 $O(\log \log(1/\epsilon))$

### 2.6.3 内点法 / Interior Point Methods

**算法 2.3** (内点法 / Interior Point Method)
内点法通过引入障碍函数将约束优化问题转化为无约束问题：
$$\min_{x} f(x) - \mu \sum_{i=1}^m \log(-g_i(x))$$

其中 $\mu > 0$ 是障碍参数。

## 2.7 形式化实现 / Formal Implementation

### 2.7.1 Lean 4 实现 / Lean 4 Implementation

```lean
-- 优化问题的定义
structure OptimizationProblem (n : ℕ) where
  objective : ℝ^n → ℝ
  inequality_constraints : List (ℝ^n → ℝ)
  equality_constraints : List (ℝ^n → ℝ)

-- 可行域
def feasible_region {n : ℕ} (P : OptimizationProblem n) : Set (ℝ^n) :=
  { x : ℝ^n | 
    (∀ g ∈ P.inequality_constraints, g x ≤ 0) ∧
    (∀ h ∈ P.equality_constraints, h x = 0) }

-- 全局最优解
def global_optimal {n : ℕ} (P : OptimizationProblem n) (x* : ℝ^n) : Prop :=
  x* ∈ feasible_region P ∧
  ∀ x ∈ feasible_region P, P.objective x* ≤ P.objective x

-- 拉格朗日函数
def lagrangian {n : ℕ} (P : OptimizationProblem n) 
  (x : ℝ^n) (λ : ℝ^m) (μ : ℝ^p) : ℝ :=
  P.objective x + 
  ∑ i, λ[i] * P.inequality_constraints[i] x +
  ∑ j, μ[j] * P.equality_constraints[j] x

-- KKT条件
structure KKT_Conditions {n m p : ℕ} (P : OptimizationProblem n) (x* : ℝ^n) where
  stationarity : ∇(lagrangian P x* λ* μ*) = 0
  primal_feasibility : x* ∈ feasible_region P
  dual_feasibility : λ* ≥ 0
  complementary_slackness : ∀ i, λ*[i] * P.inequality_constraints[i] x* = 0

-- 梯度下降法
def gradient_descent {n : ℕ} (f : ℝ^n → ℝ) (∇f : ℝ^n → ℝ^n) 
  (x0 : ℝ^n) (α : ℝ) (max_iter : ℕ) : ℝ^n :=
  let rec iterate (x : ℝ^n) (k : ℕ) : ℝ^n :=
    if k ≥ max_iter then x
    else iterate (x - α • ∇f x) (k + 1)
  iterate x0 0

-- 牛顿法
def newton_method {n : ℕ} (f : ℝ^n → ℝ) (∇f : ℝ^n → ℝ^n) (∇²f : ℝ^n → Matrix ℝ n n)
  (x0 : ℝ^n) (max_iter : ℕ) : ℝ^n :=
  let rec iterate (x : ℝ^n) (k : ℕ) : ℝ^n :=
    if k ≥ max_iter then x
    else 
      let d := -(∇²f x)⁻¹ • ∇f x
      iterate (x + d) (k + 1)
  iterate x0 0
```

### 2.7.2 Haskell 实现 / Haskell Implementation

```haskell
-- 优化问题的数据类型
data OptimizationProblem n = OptimizationProblem
  { objective :: Vector n ℝ -> ℝ
  , inequalityConstraints :: [Vector n ℝ -> ℝ]
  , equalityConstraints :: [Vector n ℝ -> ℝ]
  }

-- 可行域
feasibleRegion :: OptimizationProblem n -> Set (Vector n ℝ)
feasibleRegion p = Set.fromList [x | x <- allVectors, isFeasible p x]
  where
    isFeasible p x = all (\g -> g x <= 0) (inequalityConstraints p) &&
                     all (\h -> h x == 0) (equalityConstraints p)

-- 全局最优解
globalOptimal :: OptimizationProblem n -> Vector n ℝ -> Bool
globalOptimal p x* = x* `Set.member` feasibleRegion p &&
                     all (\x -> objective p x* <= objective p x) (feasibleRegion p)

-- 拉格朗日函数
lagrangian :: OptimizationProblem n -> Vector n ℝ -> Vector m ℝ -> Vector p ℝ -> ℝ
lagrangian p x λ μ = objective p x + 
                     sum [λ[i] * g x | (i, g) <- zip [0..] (inequalityConstraints p)] +
                     sum [μ[j] * h x | (j, h) <- zip [0..] (equalityConstraints p)]

-- KKT条件
data KKTConditions n m p = KKTConditions
  { stationarity :: Vector (n + m + p) ℝ
  , primalFeasibility :: Bool
  , dualFeasibility :: Bool
  , complementarySlackness :: Bool
  }

-- 梯度下降法
gradientDescent :: (Vector n ℝ -> ℝ) -> (Vector n ℝ -> Vector n ℝ) -> 
                  Vector n ℝ -> ℝ -> Int -> Vector n ℝ
gradientDescent f ∇f x0 α maxIter = iterate x0 0
  where
    iterate x k
      | k >= maxIter = x
      | otherwise = iterate (x - α *^ ∇f x) (k + 1)

-- 牛顿法
newtonMethod :: (Vector n ℝ -> ℝ) -> (Vector n ℝ -> Vector n ℝ) -> 
               (Vector n ℝ -> Matrix n n ℝ) -> Vector n ℝ -> Int -> Vector n ℝ
newtonMethod f ∇f ∇²f x0 maxIter = iterate x0 0
  where
    iterate x k
      | k >= maxIter = x
      | otherwise = iterate (x + d) (k + 1)
      where
        d = negate (inv (∇²f x) `multiply` ∇f x)

-- 内点法
interiorPointMethod :: OptimizationProblem n -> Vector n ℝ -> ℝ -> Vector n ℝ
interiorPointMethod p x0 μ = 
  let barrierFunction x = objective p x - μ * sum [log (-g x) | g <- inequalityConstraints p]
  in gradientDescent barrierFunction (gradient barrierFunction) x0 0.01 1000
```

## 2.8 应用与计算 / Applications and Computations

### 2.8.1 线性规划 / Linear Programming

**定义 2.11** (线性规划 / Linear Programming)
线性规划是目标函数和约束都是线性的优化问题：
$$\min_{x} c^T x$$
$$\text{subject to } Ax \leq b, x \geq 0$$

**算法**：

- 单纯形法（Simplex Method）
- 内点法（Interior Point Method）

### 2.8.2 二次规划 / Quadratic Programming

**定义 2.12** (二次规划 / Quadratic Programming)
二次规划是目标函数为二次函数的优化问题：
$$\min_{x} \frac{1}{2} x^T Q x + c^T x$$
$$\text{subject to } Ax \leq b$$

### 2.8.3 凸优化 / Convex Optimization

**定义 2.13** (凸优化 / Convex Optimization)
凸优化是目标函数和约束都是凸函数的优化问题。

**算法**：

- 梯度下降法
- 牛顿法
- 内点法

## 2.9 高级主题 / Advanced Topics

### 2.9.1 随机优化 / Stochastic Optimization

**定义 2.14** (随机优化 / Stochastic Optimization)
随机优化处理目标函数或约束包含随机变量的优化问题：
$$\min_{x} \mathbb{E}[f(x, \xi)]$$

### 2.9.2 多目标优化 / Multi-Objective Optimization

**定义 2.15** (多目标优化 / Multi-Objective Optimization)
多目标优化同时优化多个目标函数：
$$\min_{x} (f_1(x), f_2(x), \ldots, f_k(x))$$

### 2.9.3 全局优化 / Global Optimization

**定义 2.16** (全局优化 / Global Optimization)
全局优化寻找非凸函数的全局最优解。

**算法**：

- 遗传算法
- 模拟退火
- 粒子群优化

## 2.10 总结 / Summary

优化理论为各种实际问题提供了强大的数学工具和算法。

### 2.10.1 主要成果 / Main Results

1. **最优性条件**：KKT条件为约束优化提供了必要条件
2. **对偶理论**：拉格朗日对偶为优化问题提供了新的视角
3. **算法设计**：梯度下降、牛顿法、内点法等高效算法
4. **收敛性分析**：各种算法的收敛性理论和复杂度分析

### 2.10.2 应用领域 / Applications

- **机器学习**：支持向量机、神经网络训练
- **金融工程**：投资组合优化、风险管理
- **工程设计**：结构优化、参数估计
- **经济学**：效用最大化、成本最小化

---

**参考文献 / References**:

1. Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.
2. Nocedal, J., & Wright, S. J. (2006). *Numerical Optimization*. Springer.
3. Bertsekas, D. P. (1999). *Nonlinear Programming*. Athena Scientific.
4. Rockafellar, R. T. (1970). *Convex Analysis*. Princeton University Press.
